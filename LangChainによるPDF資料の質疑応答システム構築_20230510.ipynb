{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b8559dfd-b5b9-46bd-910a-57bc15765242",
      "metadata": {
        "id": "b8559dfd-b5b9-46bd-910a-57bc15765242"
      },
      "source": [
        "# LangChainによるPDF資料の質疑応答システム構築\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. ライブラリをインストールします "
      ],
      "metadata": {
        "id": "422HlAl0RS6a"
      },
      "id": "422HlAl0RS6a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7688495-ef79-4831-95bc-8c77eeb9b97d",
      "metadata": {
        "tags": [],
        "id": "c7688495-ef79-4831-95bc-8c77eeb9b97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "27ff1d5c-fcf3-42b9-da59-300d2ea1661c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.166-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.3.22-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-3.8.1-py3-none-any.whl (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.8/248.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-3.30.0-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hnswlib>=0.7 (from chromadb)\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb)\n",
            "  Downloading clickhouse_connect-0.5.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.6/922.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.2.2 (from chromadb)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Collecting fastapi>=0.85.1 (from chromadb)\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Collecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio)\n",
            "  Downloading gradio_client-0.2.4-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio)\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting starlette<0.27.0,>=0.26.1 (from fastapi>=0.85.1->chromadb)\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=2.2.2->chromadb)\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.2.2->chromadb)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (16.0.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: hnswlib, sentence-transformers, ffmpy\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2119638 sha256=d003c439167badae11fc0be869fb9dcebad88345b57a3edcbff105b52fbe0139\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=385eb341bcf93ecce676bb8c890acd8caa7d791abc735721ef25fbc436336822\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=c28bb69023fa0ec659e9994a68007d04974b0755b35ca1d7bf6198966c4e27eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built hnswlib sentence-transformers ffmpy\n",
            "Installing collected packages: tokenizers, sentencepiece, pydub, monotonic, ffmpy, zstandard, websockets, uvloop, uc-micro-py, semantic-version, requests, python-multipart, python-dotenv, pypdf, orjson, mypy-extensions, multidict, marshmallow, lz4, httptools, hnswlib, h11, frozenlist, backoff, async-timeout, aiofiles, yarl, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, openapi-schema-pydantic, mdit-py-plugins, marshmallow-enum, linkify-it-py, huggingface-hub, httpcore, clickhouse-connect, aiosignal, transformers, httpx, fastapi, dataclasses-json, aiohttp, openai, langchain, gradio-client, gradio, sentence-transformers, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 backoff-2.2.1 chromadb-0.3.22 clickhouse-connect-0.5.24 dataclasses-json-0.5.7 fastapi-0.95.1 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.30.0 gradio-client-0.2.4 h11-0.14.0 hnswlib-0.7.0 httpcore-0.17.0 httptools-0.5.0 httpx-0.24.0 huggingface-hub-0.14.1 langchain-0.0.166 linkify-it-py-2.0.2 lz4-4.3.2 marshmallow-3.19.0 marshmallow-enum-1.5.1 mdit-py-plugins-0.3.3 monotonic-1.6 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.6 openapi-schema-pydantic-1.2.4 orjson-3.8.12 posthog-3.0.1 pydub-0.25.1 pypdf-3.8.1 python-dotenv-1.0.0 python-multipart-0.0.6 requests-2.30.0 semantic-version-2.10.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 starlette-0.26.1 tiktoken-0.4.0 tokenizers-0.13.3 transformers-4.29.1 typing-inspect-0.8.0 uc-micro-py-1.0.2 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 yarl-1.9.2 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai chromadb tiktoken pypdf gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "openAIからAPI_KEYを取得してこちらに貼って下さい"
      ],
      "metadata": {
        "id": "za1alDFWM2c0"
      },
      "id": "za1alDFWM2c0"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"*******\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": 2,
      "outputs": [],
      "id": "dNA4TsHpu6OM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ライブラリをインポートします"
      ],
      "metadata": {
        "id": "LbOjBDOvRe-E"
      },
      "id": "LbOjBDOvRe-E"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4793f8d6-bf79-4513-8a31-06e209852a59",
      "metadata": {
        "tags": [],
        "id": "4793f8d6-bf79-4513-8a31-06e209852a59"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cd5ba580-2c29-450b-bb9c-edd301a7da4d",
      "metadata": {
        "tags": [],
        "id": "cd5ba580-2c29-450b-bb9c-edd301a7da4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2b4b5bcf-37f9-47be-db53-54c75d6c8ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Q: What did the fish say when it hit the wall?\n",
            "A: Dam!\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAI(temperature=0, max_tokens=-1)\n",
        "print(llm(\"tell me a joke\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PDFファイルをインポートします\n",
        "- 「格付け分類モデルにおける機械学習の応用：機械学習の説明可能性を高める手法」日本銀行ワーキングペーパーシリーズ 2023年3月 橋本龍一郎 三浦翔 吉崎康則\n",
        "\n"
      ],
      "metadata": {
        "id": "EbUkPWU7RDMF"
      },
      "id": "EbUkPWU7RDMF"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.boj.or.jp/research/wps_rev/wps_2023/data/wp23j03.pdf"
      ],
      "metadata": {
        "id": "Q-oEx4BxNpch"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "Q-oEx4BxNpch"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R82n5AhITTHx",
        "outputId": "8e48dee7-3ed5-4c24-d628-4da6a0eabb29"
      },
      "id": "R82n5AhITTHx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  wp23j03.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. RetrievalQAを使ってQAシステムのパイプラインを構築します "
      ],
      "metadata": {
        "id": "8j-swSxYR8Zw"
      },
      "id": "8j-swSxYR8Zw"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac9d4a44-da40-48f7-b5b6-ab503d0afa3d",
      "metadata": {
        "tags": [],
        "id": "ac9d4a44-da40-48f7-b5b6-ab503d0afa3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "47faaf8d-491c-4774-feeb-c93fa57489f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ],
      "source": [
        "# 1.PDF資料をロードします (load document)\n",
        "loader = PyPDFLoader(\"wp23j03.pdf\")\n",
        "documents = loader.load()\n",
        "# 2.ドキュメントをチャンクに分割します (split the documents into chunks)\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "# 3.埋め込みベクトル用モデルを選択します (select which embeddings we want to use)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "# 4.ベクトル格納のためのDBを作成します (create the vectorestore to use as the index)\n",
        "db = Chroma.from_documents(texts, embeddings)\n",
        "# 5.リトリバーにより、質問と関連するチャンクを呼び出します　(expose this index in a retriever interface)\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
        "# 6.回答を作成するためのchainを作ります（create a chain to answer questions） \n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(), chain_type=\"map_reduce\", retriever=retriever, return_source_documents=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"このレポートでは、どのような分析手法が用いられてますか? \"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BRTQbw5Wylmv",
        "outputId": "fdff2356-136a-41c9-c8c4-02d556b309ba"
      },
      "id": "BRTQbw5Wylmv",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' このレポートでは、機械学習、順序ロジット回帰、SHAPやPDPなどのXAI（説明可能性を高める枠組み）を用いて分析が行われています。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"このレポートでは、どのような分析手法が用いられてますか? \"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y_RO2FRjUEL2",
        "outputId": "b23b350e-073e-4dff-d00f-07e293620059"
      },
      "id": "y_RO2FRjUEL2",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'このレポートでは、どのような分析手法が用いられてますか? answer in Japanese',\n",
              " 'result': ' 本レポートでは、機械学習を用いた格付け分類モデルの推計と、SHAPやPDPといった機械学習の説明可能性を高める枠組み（XAI）を用いて分析が行われています。',\n",
              " 'source_documents': [Document(page_content='格付け分類モデルにおける機械学習の 応用： \\n機械学習の 説明可能性 を高める 手法 \\n橋本龍一郎 * \\nryuuichirou.hashimoto@boj.or.jp  \\n三浦翔 * \\nkakeru.miura @boj.or.jp  \\n吉崎康則 * \\nyasunori.yoshizaki@boj.or.jp  \\nNo.23-J-3 \\n2023年3月 日本銀行  \\n〒103-8660 日本郵便（株）日本橋郵便局私書箱 30号 \\n*金融機構局\\n日本銀行ワーキングペーパーシリーズは、日本銀行員および外部研究者の研究成果を\\nとりまとめたもので、内外の研究機関、研究者等の有識者から幅広くコメントを頂戴す\\nることを意図しています。ただし、論文の中で示された内容や意見は、日本銀行の公式\\n見解を示すものではありません。  \\nなお、ワーキングペーパーシリーズに対するご意見・ご質問や、掲載ファイルに関する\\nお問い合わせは、執筆者までお寄せ下さい。  \\n商用目的で転載・複製を行う場合は、予め日本銀行情報サービス局\\n(post.prd8@boj.or.jp) までご相談下さい。転載・複製を行う場合は、出所を明記して\\n下さい。  \\n日本銀行ワーキングペーパーシリーズ', metadata={'source': 'wp23j03.pdf', 'page': 0}),\n",
              "  Document(page_content='23 デルの予測結果に与える解釈は、 幾つかの重要な 仮定に依拠して いる点には留意が必\\n要である。 こうした仮定を把握せずに XAIを機械学習モデルに適用することで、モデ\\nルから誤った帰結を得てしまう可能性がある。 XAIを用いる際には、当該手法の仮定\\nや前提を把握し検証を行うことが重要と考えられる。  \\nまた、本章では説明を簡便にするために IG/Non-IGの2クラス問題について XAIを\\n適用したが、多クラス 分類問題の場合 には、SHAPやPDPはクラスの数だけ作成され\\nる。すなわち、 5クラス問題であれば、 あるサンプルにおける特定の説明変数の SHAP\\n値は5つ作成される。 多クラスの SHAPやPDPの算出にはより多くの時間的コスト\\nを要するのみならず、算出結果の解釈が容易でない可能性がある。 これに対し、ロジ\\nット回帰など従来のパラメトリックな 手法は、関数形や分布を明示的に仮定するため、\\n各説明変数が予測値に与える影響を回帰係数から容易に把握できるという点で、安定\\n的に高い説明可能性が担保されているといえる。 こうした点を踏まえると、 XAIによ\\nる機械学習モデルの解釈が困難である場合 などには、パラメトリックな手法を用いて\\n推計したモデルも併用し、予測精度とモデルの 説明可能性 を相互補完することも 有用\\nである。 \\n５．おわりに  \\n本稿では、格付け分類モデルの推計に機械学習を応用し、従来広く用いられてきた\\n順序ロジット回帰との予測精度の比較を行った。 機械学習は、モデルの構造上、説明\\n変数と被説明変数の間の複雑な非線形性を取り込むことが可能である。 その結果、デ\\nフォルト率の推計に機械学習を応用した先行研究と同様、 従来のパラメトリックな手\\n法対比、 予測精度の 大幅な改善がみられた。  \\nまた、SHAPやPDPといった機械学習の説明可能性を高める枠組み （XAI）を用い\\nて、企業の財務指標と信用力の関係について定量的な分析を行った。その結果、 ICR\\nやレバレッジ比率などの財務指標と信用力との関係において、非線形性が存在するこ\\nとなどが分かった。 こうした枠組みを用いることで、これ まで機械学習の 課題の一つ\\nとして捉えられることが多かった説明可能性の低さ に一定程度 対処することができ\\nることが確認された。  \\n機械学習の説明可能性を高める手法は近年研究が著しく進展し ている分野であり、\\n今後も新たな指標が開発されることが予想される。 金融機関の業務における機械学習\\nの活用が浸透していくもとで、こうした手法の重要性や有用性は今後も高まっていく\\nと考えられる。', metadata={'source': 'wp23j03.pdf', 'page': 23})]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"このレポートでは、どのように格付けを予測していますか？500字で説明して下さい。\"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ec404f8-4ea3-4a83-bfe8-76e360cd3db1",
        "id": "dL0mXUVUXZDG"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'このレポートでは、どのように格付けを予測していますか？500字で説明して下さい。answer in Japanese',\n",
              " 'result': ' このレポートでは、順序ロジット回帰とLGBMの2つのモデルを用いて、格付けを予測しています。まず、学習において、データセットの分割（訓練データとテストデータ）を行い、訓練データを使用してモデルを構築します。次に、テストデータを使用してモデルの予測性能を評価し、全サンプルの正答率を求めます。全サンプルの 正答率は、5クラス問題では、順序ロジット回帰が43.1％、LGBMが79.4',\n",
              " 'source_documents': [Document(page_content='格付け分類モデルにおける機械学習の 応用： \\n機械学習の 説明可能性 を高める 手法 \\n橋本龍一郎 * \\nryuuichirou.hashimoto@boj.or.jp  \\n三浦翔 * \\nkakeru.miura @boj.or.jp  \\n吉崎康則 * \\nyasunori.yoshizaki@boj.or.jp  \\nNo.23-J-3 \\n2023年3月 日本銀行  \\n〒103-8660 日本郵便（株）日本橋郵便局私書箱 30号 \\n*金融機構局\\n日本銀行ワーキングペーパーシリーズは、日本銀行員および外部研究者の研究成果を\\nとりまとめたもので、内外の研究機関、研究者等の有識者から幅広くコメントを頂戴す\\nることを意図しています。ただし、論文の中で示された内容や意見は、日本銀行の公式\\n見解を示すものではありません。  \\nなお、ワーキングペーパーシリーズに対するご意見・ご質問や、掲載ファイルに関する\\nお問い合わせは、執筆者までお寄せ下さい。  \\n商用目的で転載・複製を行う場合は、予め日本銀行情報サービス局\\n(post.prd8@boj.or.jp) までご相談下さい。転載・複製を行う場合は、出所を明記して\\n下さい。  \\n日本銀行ワーキングペーパーシリーズ', metadata={'source': 'wp23j03.pdf', 'page': 0}),\n",
              "  Document(page_content='13 ３－１． 正答率による予測精度の評価  \\nまず、正答率を確認する。 図表9は、予測された 格付けを横軸に、実際の 格付けを\\n縦軸に集計した 混合行列 （Confusion matrix ）である。正答率は、モデルが正しく 格付\\nけを判別できた企業の割合であ り、ここでは、 混合行列の対角成分の和をサンプル数\\nで割ることによって 、全サンプルの正答率 を定義する 。全サンプルの 正答率は、5ク\\nラス問題では、 順序ロジット 回帰が43.1％、LGBMが79.4％となっており、 いずれの\\nモデルでも実際の格付 けとの乖離はみられるが、 LGBMの正答率 の方が高い結果とな\\nった。順序ロジット 回帰の混合行列を仔細にみると、両端（ A格以上、 CCC格以下）\\nの正答率は 55～60％と相応に高い一方で、それ以外の 格付けでは正答率が 30％台と\\n低いことが 分かる。この背景として、順序 ロジット 回帰では、2章で述べた財務指標\\nと格付け間の非線形性や、財務指標 の分散と格付け間の相関といった 複雑な関係 性を\\n捕捉することが難しいこと などが考えられる。 なお、2クラス問題 では、ロジット回\\n帰が77.7％、LGBMが89.6％と、5クラス問題同様、 LGBMの方が正答率 が高い。  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n【順序ロジット 回帰】 \\n①5クラス問題  \\n【LGBM】 \\n図表9 混合行列  \\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 5,992 569 139 48 15 88.6\\nBBB格 681 6,965 723 223 75 80.4\\nBB格 132 528 3,796 628 159 72.4\\nB格 53 234 645 5,171 831 74.6\\nCCC格以下 7 49 129 590 3,024 79.6\\n全サンプル正答率： 79.4予測\\n実\\n際\\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 4,049 1,716 710 183 105 59.9\\nBBB格 2,593 2,953 2,240 743 138 34.1\\nBB格 626 1,015 1,947 1,308 347 37.1\\nB格 260 556 1,473 2,450 2,195 35.3\\nCCC格以下 57 127 376 1,108 2,131 56.1\\n全サンプル正答率： 43.1予測\\n実\\n際\\n（注）テストデータ を用いて 算出。各セルは企業数に応じて色付け している。', metadata={'source': 'wp23j03.pdf', 'page': 13})]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "id": "dL0mXUVUXZDG"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"なぜ格付の予測が必要なのですか？\"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f6bd7baf-1fa4-48fa-8cda-741d4cdb9586",
        "id": "MbR_lUVkXzG8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'なぜ格付の予測が必要なのですか？answer in Japanese',\n",
              " 'result': ' 機械学習を使用することにより、金融機関の業務をより効率的に管理することができるため、格付の予測が必要です。',\n",
              " 'source_documents': [Document(page_content='格付け分類モデルにおける機械学習の 応用： \\n機械学習の 説明可能性 を高める 手法 \\n橋本龍一郎 * \\nryuuichirou.hashimoto@boj.or.jp  \\n三浦翔 * \\nkakeru.miura @boj.or.jp  \\n吉崎康則 * \\nyasunori.yoshizaki@boj.or.jp  \\nNo.23-J-3 \\n2023年3月 日本銀行  \\n〒103-8660 日本郵便（株）日本橋郵便局私書箱 30号 \\n*金融機構局\\n日本銀行ワーキングペーパーシリーズは、日本銀行員および外部研究者の研究成果を\\nとりまとめたもので、内外の研究機関、研究者等の有識者から幅広くコメントを頂戴す\\nることを意図しています。ただし、論文の中で示された内容や意見は、日本銀行の公式\\n見解を示すものではありません。  \\nなお、ワーキングペーパーシリーズに対するご意見・ご質問や、掲載ファイルに関する\\nお問い合わせは、執筆者までお寄せ下さい。  \\n商用目的で転載・複製を行う場合は、予め日本銀行情報サービス局\\n(post.prd8@boj.or.jp) までご相談下さい。転載・複製を行う場合は、出所を明記して\\n下さい。  \\n日本銀行ワーキングペーパーシリーズ', metadata={'source': 'wp23j03.pdf', 'page': 0}),\n",
              "  Document(page_content='1 格付け分類モデルにおける機械学習の 応用： \\n機械学習の 説明可能性 を高める手法* \\n \\n橋本龍一郎†・三浦翔‡・吉崎康則§ \\n \\n2023年3月 \\n \\n【要旨】  \\n \\n近年、金融機関における様々な業務において機械学習の活用 が進んでいる。\\n信用リスク管理の分野では、 クレジットスコアリングモデルや デフォルト率\\nモデルに機械学習を 活用する事例がみられ始めて いる。本稿では、 格付け分\\n類モデルの推計に機械学習を応用した。まず、 説明変数等の条件を揃えたう\\nえで、機械学習と順序ロジット回帰によって格付け分類モデルを推計し、モ\\nデル構造の差異によって、どの程度予測精度に違いが生じるのかを確認した 。\\n次に、近年急速に研究が進んでいる機械学習の 説明可能性 を高めるための手\\n法（ 「説明可能な AI」）を応用して、 変数重要度の 計測やモデル予測値の要因\\n分解を行った 。分析結果は以下の通りである。第一に、機械学習 の応用によ\\nり、財務指標と 信用力の非線形的な関係 が捕捉しやすく なり、順序ロジット\\n対比で大幅に予測精度が改善した。第二に、 SHAP（SHapley Additive \\nexPlanations ）やPDP（Partial Dependence Plot ）を用いて モデル予測値の要因分\\n解を行うことで、 売上高、総資産回転率や ICRといった財務指標が企業の信\\n用力に与える影響が大きいことが分かったほか、 ICRが2倍以下に低下する\\nと信用力が急激に減少するといった非線形性が観察された。 これらの 説明可\\n能性を高めるために用いる手法 の仮定や 限界を正しく把握しつつ活用するこ\\nとで、機械学習の課題の 一つである説明可能性の低さを補完することが可能\\nとなる。  \\n \\n \\nJEL分類番号： C49、C55、G32 \\nキーワード： 信用リスク管理 、機械学習、 説明可能性 、説明可能な AI \\n                                                        \\n*  本稿の作成に当たっては、多くの日本銀行スタッフから有益なコメントを頂いた。ここに記し\\nて感謝したい。ただし、本稿に示されている意見は 、筆者達個人に属し、日本銀行の公式見解を\\n示すものではない。また、ありうべき誤りはすべて筆者達個人に属する。  \\n† 日本銀行金融機構局（ ryuuichirou.hashimoto@boj.or.jp ） \\n‡ 日本銀行金融機構局（ kakeru.miura@boj.or.jp ） \\n§ 日本銀行金融機構局（ yasunori.yoshizaki@boj.or.jp ）', metadata={'source': 'wp23j03.pdf', 'page': 1})]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "id": "MbR_lUVkXzG8"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"金融機関はどのように格付けを利用していますか？\"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1307361-5524-4e02-a098-eb069f748f1f",
        "id": "LQNRrj1CYJ38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '金融機関はどのように格付けを利用していますか？answer in Japanese',\n",
              " 'result': ' 金融機関は、個別企業の財務データやマクロ経済変数から、個別債務者の信用力を予測するモデルを中心に、機械学習を活用して格付けを行っています。',\n",
              " 'source_documents': [Document(page_content='格付け分類モデルにおける機械学習の 応用： \\n機械学習の 説明可能性 を高める 手法 \\n橋本龍一郎 * \\nryuuichirou.hashimoto@boj.or.jp  \\n三浦翔 * \\nkakeru.miura @boj.or.jp  \\n吉崎康則 * \\nyasunori.yoshizaki@boj.or.jp  \\nNo.23-J-3 \\n2023年3月 日本銀行  \\n〒103-8660 日本郵便（株）日本橋郵便局私書箱 30号 \\n*金融機構局\\n日本銀行ワーキングペーパーシリーズは、日本銀行員および外部研究者の研究成果を\\nとりまとめたもので、内外の研究機関、研究者等の有識者から幅広くコメントを頂戴す\\nることを意図しています。ただし、論文の中で示された内容や意見は、日本銀行の公式\\n見解を示すものではありません。  \\nなお、ワーキングペーパーシリーズに対するご意見・ご質問や、掲載ファイルに関する\\nお問い合わせは、執筆者までお寄せ下さい。  \\n商用目的で転載・複製を行う場合は、予め日本銀行情報サービス局\\n(post.prd8@boj.or.jp) までご相談下さい。転載・複製を行う場合は、出所を明記して\\n下さい。  \\n日本銀行ワーキングペーパーシリーズ', metadata={'source': 'wp23j03.pdf', 'page': 0}),\n",
              "  Document(page_content='2 １．はじめに  \\n近年、金融機関における様々な業務において機械学習の活用が 進んでいる。Bank of \\nEngland (2022) によれば、実務において機械学習を活用する英国の金融機関の割合は 7\\n割強を占めるに至っており、顧客との関係構築、 マネー・ロンダリング防止対策や 各\\n種リスク管理、 粉飾決算の検出 など幅広い業務分野で活用されている1。 \\n信用リスク管理の分野では、 European Banking Authority (2021) （以下、 EBA (2021)）\\nが指摘するように、 クレジットスコアリングモデルやデフォルト率モデルなど、個別\\n企業の財務データやマクロ経済変数から、個別債務 者の信用力を予測するモデルを中\\n心に、機械学習 を活用する事例 がみられ始めて いる。 \\n従来、こうしたデフォルトや 格付けの決定要因の分析には、主に ロジット 回帰など\\nパラメトリックな手法が用いられてきた。 近年、デフォルト率モデルの分野 において\\nは、機械学習では、より複雑な非線形 性を捕捉可能なことから、 パラメトリックな手\\n法対比、デフォルト率の予測精度が向上するとの実証研究が多くみられている。例え\\nば、Alonso and Carbó (2021)は、スペインの個別行におけるリテールローンのデータを\\n用いて、機械学習では、 ロジット 回帰対比、デフォルト 率の予測精度が向上すること\\nを示した。 また、三浦ほか  (2019)は、入出金情報を用いて、中堅中小企業を中心とし\\nた非上場企業にも適用可能なデフォルト率モデルを構築し、機械学習では、ロジット\\n回帰対比、予測精度が向上することを示した。  \\n他方、格付け分類モデル の分野において は、小林  (2001)2など幾つかの先行研究が\\nみられているが、パラメトリックな手法が中心であり、 機械学習を応用した分析は少\\nない。格付け分類モデルは、 企業の財務指標やマクロ変数から、個別企業の格付けを\\n推定する 枠組みである。一般に、機械学習は、複雑なモデル構造を取り得るため、財\\n務指標（説明変数）と格付け（被説明変数）の間に非線形性が存在する場合、パラメ\\nトリックな手法に比して予測精度が高くなりやす く、機械学習を応用するメリットは\\n大きいと考えられる。 機械学習の応用により、 格付け分類モデルの 予測精度の向上 が\\n実現できれば 、個別企業の信用リスク評価の精緻化にとどまらず、これを応用したシ\\nナリオ分析の有用性の向上も期待 できる3。 \\n                                                        \\n1 機械学習は、民間金融機関だけでなく、中央銀行においても活用が広がっている。 Araujo et al. \\n(2022)は、 データの収集、 金融・経済分析、 金融政策運営、 プルーデンス業務など、 中央銀行の様々\\nな業務で機械学習が活用されている点を指摘している。  \\n2  わが国製造業のデータを用いて、財務指標を説明変数、社債格付けを被説明変数とする順序プ\\nロビット回帰と多項プロビット回帰を推計している。  \\n3 2022年10月の金融システムレポートでは、機械学習の手法に基づく格付け分類モデルを用い\\nて、資金調達コスト上昇に伴う ICRの悪化が、デフォルトカーブに及ぼす影響を推計し ている。\\n詳細は日本銀行  (2022)を参照。', metadata={'source': 'wp23j03.pdf', 'page': 2})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "id": "LQNRrj1CYJ38"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"機械学習とロジット回帰ではどちらが精度が良いですか？ 400字以内で答えて下さい。\"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bd7bcc7b-bae8-4567-c219-840ea6235a91",
        "id": "LUfkL8-uY5nW"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '機械学習とロジット回帰ではどちらが精度が良いですか？ 400字以内で答えて下さい。answer in Japanese',\n",
              " 'result': ' アルゾンとカーボー（2021）や三浦ら（2019）の研究から、機械学習のLightGBMモデルは順序ロジット回帰よりも精度が高いことが分かりました。',\n",
              " 'source_documents': [Document(page_content='13 ３－１． 正答率による予測精度の評価  \\nまず、正答率を確認する。 図表9は、予測された 格付けを横軸に、実際の 格付けを\\n縦軸に集計した 混合行列 （Confusion matrix ）である。正答率は、モデルが正しく 格付\\nけを判別できた企業の割合であ り、ここでは、 混合行列の対角成分の和をサンプル数\\nで割ることによって 、全サンプルの正答率 を定義する 。全サンプルの 正答率は、5ク\\nラス問題では、 順序ロジット 回帰が43.1％、LGBMが79.4％となっており、 いずれの\\nモデルでも実際の格付 けとの乖離はみられるが、 LGBMの正答率 の方が高い結果とな\\nった。順序ロジット 回帰の混合行列を仔細にみると、両端（ A格以上、 CCC格以下）\\nの正答率は 55～60％と相応に高い一方で、それ以外の 格付けでは正答率が 30％台と\\n低いことが 分かる。この背景として、順序 ロジット 回帰では、2章で述べた財務指標\\nと格付け間の非線形性や、財務指標 の分散と格付け間の相関といった 複雑な関係 性を\\n捕捉することが難しいこと などが考えられる。 なお、2クラス問題 では、ロジット回\\n帰が77.7％、LGBMが89.6％と、5クラス問題同様、 LGBMの方が正答率 が高い。  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n【順序ロジット 回帰】 \\n①5クラス問題  \\n【LGBM】 \\n図表9 混合行列  \\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 5,992 569 139 48 15 88.6\\nBBB格 681 6,965 723 223 75 80.4\\nBB格 132 528 3,796 628 159 72.4\\nB格 53 234 645 5,171 831 74.6\\nCCC格以下 7 49 129 590 3,024 79.6\\n全サンプル正答率： 79.4予測\\n実\\n際\\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 4,049 1,716 710 183 105 59.9\\nBBB格 2,593 2,953 2,240 743 138 34.1\\nBB格 626 1,015 1,947 1,308 347 37.1\\nB格 260 556 1,473 2,450 2,195 35.3\\nCCC格以下 57 127 376 1,108 2,131 56.1\\n全サンプル正答率： 43.1予測\\n実\\n際\\n（注）テストデータ を用いて 算出。各セルは企業数に応じて色付け している。', metadata={'source': 'wp23j03.pdf', 'page': 13}),\n",
              "  Document(page_content='2 １．はじめに  \\n近年、金融機関における様々な業務において機械学習の活用が 進んでいる。Bank of \\nEngland (2022) によれば、実務において機械学習を活用する英国の金融機関の割合は 7\\n割強を占めるに至っており、顧客との関係構築、 マネー・ロンダリング防止対策や 各\\n種リスク管理、 粉飾決算の検出 など幅広い業務分野で活用されている1。 \\n信用リスク管理の分野では、 European Banking Authority (2021) （以下、 EBA (2021)）\\nが指摘するように、 クレジットスコアリングモデルやデフォルト率モデルなど、個別\\n企業の財務データやマクロ経済変数から、個別債務 者の信用力を予測するモデルを中\\n心に、機械学習 を活用する事例 がみられ始めて いる。 \\n従来、こうしたデフォルトや 格付けの決定要因の分析には、主に ロジット 回帰など\\nパラメトリックな手法が用いられてきた。 近年、デフォルト率モデルの分野 において\\nは、機械学習では、より複雑な非線形 性を捕捉可能なことから、 パラメトリックな手\\n法対比、デフォルト率の予測精度が向上するとの実証研究が多くみられている。例え\\nば、Alonso and Carbó (2021)は、スペインの個別行におけるリテールローンのデータを\\n用いて、機械学習では、 ロジット 回帰対比、デフォルト 率の予測精度が向上すること\\nを示した。 また、三浦ほか  (2019)は、入出金情報を用いて、中堅中小企業を中心とし\\nた非上場企業にも適用可能なデフォルト率モデルを構築し、機械学習では、ロジット\\n回帰対比、予測精度が向上することを示した。  \\n他方、格付け分類モデル の分野において は、小林  (2001)2など幾つかの先行研究が\\nみられているが、パラメトリックな手法が中心であり、 機械学習を応用した分析は少\\nない。格付け分類モデルは、 企業の財務指標やマクロ変数から、個別企業の格付けを\\n推定する 枠組みである。一般に、機械学習は、複雑なモデル構造を取り得るため、財\\n務指標（説明変数）と格付け（被説明変数）の間に非線形性が存在する場合、パラメ\\nトリックな手法に比して予測精度が高くなりやす く、機械学習を応用するメリットは\\n大きいと考えられる。 機械学習の応用により、 格付け分類モデルの 予測精度の向上 が\\n実現できれば 、個別企業の信用リスク評価の精緻化にとどまらず、これを応用したシ\\nナリオ分析の有用性の向上も期待 できる3。 \\n                                                        \\n1 機械学習は、民間金融機関だけでなく、中央銀行においても活用が広がっている。 Araujo et al. \\n(2022)は、 データの収集、 金融・経済分析、 金融政策運営、 プルーデンス業務など、 中央銀行の様々\\nな業務で機械学習が活用されている点を指摘している。  \\n2  わが国製造業のデータを用いて、財務指標を説明変数、社債格付けを被説明変数とする順序プ\\nロビット回帰と多項プロビット回帰を推計している。  \\n3 2022年10月の金融システムレポートでは、機械学習の手法に基づく格付け分類モデルを用い\\nて、資金調達コスト上昇に伴う ICRの悪化が、デフォルトカーブに及ぼす影響を推計し ている。\\n詳細は日本銀行  (2022)を参照。', metadata={'source': 'wp23j03.pdf', 'page': 2})]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "id": "LUfkL8-uY5nW"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"機械学習とロジット回帰ではどのぐらい精度に差がありますか？ 500字で答えて下さい。\"\n",
        "result = qa({\"query\": query+\"answer in Japanese\"})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1d909f8c-6081-496d-e6f1-915222872d5c",
        "id": "Tlue1-HLbWbq"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '機械学習とロジット回帰ではどのぐらい精度に差がありますか？ 500字で答えて下さい。answer in Japanese',\n",
              " 'result': ' 近年のデフォルト率モデル分野では、機械学習のLGBMの方が順序ロジット回帰より正答率が高く、5クラス問題では79.4％、2クラス問題では89.6％である一方、順序ロジット回帰では5クラス問題で43.1％、2クラス問題で77.7％となっていることから、機械学習とロジット回帰では精度にかなりの差があることがわかります。',\n",
              " 'source_documents': [Document(page_content='13 ３－１． 正答率による予測精度の評価  \\nまず、正答率を確認する。 図表9は、予測された 格付けを横軸に、実際の 格付けを\\n縦軸に集計した 混合行列 （Confusion matrix ）である。正答率は、モデルが正しく 格付\\nけを判別できた企業の割合であ り、ここでは、 混合行列の対角成分の和をサンプル数\\nで割ることによって 、全サンプルの正答率 を定義する 。全サンプルの 正答率は、5ク\\nラス問題では、 順序ロジット 回帰が43.1％、LGBMが79.4％となっており、 いずれの\\nモデルでも実際の格付 けとの乖離はみられるが、 LGBMの正答率 の方が高い結果とな\\nった。順序ロジット 回帰の混合行列を仔細にみると、両端（ A格以上、 CCC格以下）\\nの正答率は 55～60％と相応に高い一方で、それ以外の 格付けでは正答率が 30％台と\\n低いことが 分かる。この背景として、順序 ロジット 回帰では、2章で述べた財務指標\\nと格付け間の非線形性や、財務指標 の分散と格付け間の相関といった 複雑な関係 性を\\n捕捉することが難しいこと などが考えられる。 なお、2クラス問題 では、ロジット回\\n帰が77.7％、LGBMが89.6％と、5クラス問題同様、 LGBMの方が正答率 が高い。  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n【順序ロジット 回帰】 \\n①5クラス問題  \\n【LGBM】 \\n図表9 混合行列  \\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 5,992 569 139 48 15 88.6\\nBBB格 681 6,965 723 223 75 80.4\\nBB格 132 528 3,796 628 159 72.4\\nB格 53 234 645 5,171 831 74.6\\nCCC格以下 7 49 129 590 3,024 79.6\\n全サンプル正答率： 79.4予測\\n実\\n際\\nA格以上 BBB格 BB格 B格CCC格以下 正答率（％）\\nA格以上 4,049 1,716 710 183 105 59.9\\nBBB格 2,593 2,953 2,240 743 138 34.1\\nBB格 626 1,015 1,947 1,308 347 37.1\\nB格 260 556 1,473 2,450 2,195 35.3\\nCCC格以下 57 127 376 1,108 2,131 56.1\\n全サンプル正答率： 43.1予測\\n実\\n際\\n（注）テストデータ を用いて 算出。各セルは企業数に応じて色付け している。', metadata={'source': 'wp23j03.pdf', 'page': 13}),\n",
              "  Document(page_content='2 １．はじめに  \\n近年、金融機関における様々な業務において機械学習の活用が 進んでいる。Bank of \\nEngland (2022) によれば、実務において機械学習を活用する英国の金融機関の割合は 7\\n割強を占めるに至っており、顧客との関係構築、 マネー・ロンダリング防止対策や 各\\n種リスク管理、 粉飾決算の検出 など幅広い業務分野で活用されている1。 \\n信用リスク管理の分野では、 European Banking Authority (2021) （以下、 EBA (2021)）\\nが指摘するように、 クレジットスコアリングモデルやデフォルト率モデルなど、個別\\n企業の財務データやマクロ経済変数から、個別債務 者の信用力を予測するモデルを中\\n心に、機械学習 を活用する事例 がみられ始めて いる。 \\n従来、こうしたデフォルトや 格付けの決定要因の分析には、主に ロジット 回帰など\\nパラメトリックな手法が用いられてきた。 近年、デフォルト率モデルの分野 において\\nは、機械学習では、より複雑な非線形 性を捕捉可能なことから、 パラメトリックな手\\n法対比、デフォルト率の予測精度が向上するとの実証研究が多くみられている。例え\\nば、Alonso and Carbó (2021)は、スペインの個別行におけるリテールローンのデータを\\n用いて、機械学習では、 ロジット 回帰対比、デフォルト 率の予測精度が向上すること\\nを示した。 また、三浦ほか  (2019)は、入出金情報を用いて、中堅中小企業を中心とし\\nた非上場企業にも適用可能なデフォルト率モデルを構築し、機械学習では、ロジット\\n回帰対比、予測精度が向上することを示した。  \\n他方、格付け分類モデル の分野において は、小林  (2001)2など幾つかの先行研究が\\nみられているが、パラメトリックな手法が中心であり、 機械学習を応用した分析は少\\nない。格付け分類モデルは、 企業の財務指標やマクロ変数から、個別企業の格付けを\\n推定する 枠組みである。一般に、機械学習は、複雑なモデル構造を取り得るため、財\\n務指標（説明変数）と格付け（被説明変数）の間に非線形性が存在する場合、パラメ\\nトリックな手法に比して予測精度が高くなりやす く、機械学習を応用するメリットは\\n大きいと考えられる。 機械学習の応用により、 格付け分類モデルの 予測精度の向上 が\\n実現できれば 、個別企業の信用リスク評価の精緻化にとどまらず、これを応用したシ\\nナリオ分析の有用性の向上も期待 できる3。 \\n                                                        \\n1 機械学習は、民間金融機関だけでなく、中央銀行においても活用が広がっている。 Araujo et al. \\n(2022)は、 データの収集、 金融・経済分析、 金融政策運営、 プルーデンス業務など、 中央銀行の様々\\nな業務で機械学習が活用されている点を指摘している。  \\n2  わが国製造業のデータを用いて、財務指標を説明変数、社債格付けを被説明変数とする順序プ\\nロビット回帰と多項プロビット回帰を推計している。  \\n3 2022年10月の金融システムレポートでは、機械学習の手法に基づく格付け分類モデルを用い\\nて、資金調達コスト上昇に伴う ICRの悪化が、デフォルトカーブに及ぼす影響を推計し ている。\\n詳細は日本銀行  (2022)を参照。', metadata={'source': 'wp23j03.pdf', 'page': 2})]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "id": "Tlue1-HLbWbq"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}